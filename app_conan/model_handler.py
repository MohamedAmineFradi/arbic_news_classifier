"""Gestionnaire de mod√®les pour la d√©tection de fake news"""

import logging
from pathlib import Path
from typing import Dict, Any, Tuple, Optional, List
import sys

ROOT_DIR = Path(__file__).parent.parent
if str(ROOT_DIR) not in sys.path:
    sys.path.append(str(ROOT_DIR))

try:
    from src.data import ArabicTextPreprocessor
    from src.utils import load_model
    from config import MODELS_DIR
except ImportError as e:
    print(f"Erreur: Impossible d'importer les modules. ({e})")
    MODELS_DIR = Path("models")
    class ArabicTextPreprocessor:
        def preprocess(self, text): return text
    def load_model(path): return None

logger = logging.getLogger(__name__)

class ModelHandler:
    """Gestion des mod√®les ML pour la d√©tection"""
    
    MODEL_NAMES = {
        'nb': 'Na√Øve Bayes',
        'svm': 'SVM (Support Vector Machine)',
        'lr': 'R√©gression Logistique',
        'rf': 'Random Forest',
        'gb': 'Gradient Boosting',
        'arabert': 'AraBERT (Transformer)'
    }
    
    # Heuristiques inspir√©es de Detective Conan (indices de mensonge)
    SUSPICION_KEYWORDS = {
        # Mots exag√©r√©s
        'ÿØŸäŸÜÿßÿµŸàÿ±', 'ŸÅÿ∂ÿßÿ¶Ÿä', 'ŸÅÿ∂ÿßÿ¶Ÿäÿ©', 'ŸÖÿÆŸÑŸàŸÇ ÿ∫ÿ±Ÿäÿ®', 'ŸÉÿßÿ¶ŸÜ ŸÅÿ∂ÿßÿ¶Ÿä',
        # Pr√©tentions magiques
        'ŸÖÿπÿ¨ÿ≤ÿ©', 'ÿ≥ÿ≠ÿ±Ÿä', 'ÿ≥ÿ≠ÿ±Ÿäÿ©', 'ÿÆÿßÿ±ŸÇ', 'ÿÆÿßÿ±ŸÇÿ© ŸÑŸÑÿ∑ÿ®Ÿäÿπÿ©',
        # Urgence excessive
        'ÿπÿßÿ¨ŸÑ ÿ¨ÿØÿß', 'ÿπÿßÿ¨ŸÑ ŸàÿÆÿ∑Ÿäÿ±', 'ÿßŸÜÿ™ÿ®Ÿá ŸÇÿ®ŸÑ ŸÅŸàÿßÿ™ ÿßŸÑÿ£ŸàÿßŸÜ',
        # Catastrophisme
        'ŸäŸàŸÖ ÿßŸÑŸÇŸäÿßŸÖÿ©', 'ŸÜŸáÿßŸäÿ© ÿßŸÑÿπÿßŸÑŸÖ', 'ŸÉÿßÿ±ÿ´ÿ© ÿπÿßŸÑŸÖŸäÿ©', 'ÿØŸÖÿßÿ± ÿ¥ÿßŸÖŸÑ',
        # Complots
        'ÿ™ÿ≥ÿ±Ÿäÿ® ÿÆÿ∑Ÿäÿ±', 'ŸäÿÆŸÅŸàŸÜ ÿπŸÜŸÉ', 'ÿßŸÑÿ≠ŸÉŸàŸÖÿ© ÿ™ÿÆŸÅŸä', 'ŸÖÿ§ÿßŸÖÿ±ÿ© ŸÉÿ®ÿ±Ÿâ',
        # Science-fiction
        'ÿßŸÜŸÅÿ¨ÿßÿ± ÿ¥ŸÖÿ≥Ÿä', 'ÿ≠ÿ≤ÿßŸÖ ÿßŸÑŸÉŸàŸäŸÉÿ®ÿßÿ™', 'ÿ®Ÿàÿßÿ®ÿ© ÿ≤ŸÖŸÜŸäÿ©',
        # Pseudo-science
        'ÿßŸÑÿ™ŸÜÿ®ÿ§ÿßÿ™', 'ÿßŸÑÿ£ÿ®ÿ±ÿßÿ¨ ÿ™ŸÉÿ¥ŸÅ', 'ÿ∑ÿßŸÇÿ© ŸÉŸàŸÜŸäÿ©', 'ÿ¥ÿßŸÉÿ±ÿßÿ™',
        # Trop beau pour √™tre vrai
        'Ÿäÿ≠ŸàŸÑ ÿßŸÑŸÖÿßÿ° ÿ•ŸÑŸâ ŸàŸÇŸàÿØ', 'ÿπŸÑÿßÿ¨ ÿ≥ÿ≠ÿ±Ÿä', 'Ÿäÿ¥ŸÅŸä ŸÉŸÑ ÿßŸÑÿ£ŸÖÿ±ÿßÿ∂',
        'ÿßÿ±ÿ®ÿ≠ ÿßŸÑŸÖŸÑŸäŸàŸÜ', 'ŸÖÿ¨ÿßŸÜÿßŸã ÿ™ŸÖÿßŸÖÿßŸã', 'ÿ®ÿØŸàŸÜ ŸÖÿ¨ŸáŸàÿØ'
    }
    
    def __init__(self):
        self.preprocessor = ArabicTextPreprocessor()
        self.feature_extractor = None
        self.loaded_models: Dict[str, Any] = {}
        self.current_model_type = 'nb'
        
        self._load_feature_extractor()
    
    def _load_feature_extractor(self):
        """Charger l'extracteur de features TF-IDF"""
        try:
            extractor_path = MODELS_DIR / 'feature_extractor.pkl'
            if extractor_path.exists():
                self.feature_extractor = load_model(str(extractor_path))
                logger.info("‚úÖ Extracteur de features charg√©")
            else:
                logger.warning(f"‚ö†Ô∏è Extracteur introuvable: {extractor_path}")
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement extracteur: {e}")
    
    def load_model(self, model_key: str) -> bool:
        """
        Charger un mod√®le en m√©moire cache
        
        Args:
            model_key: Cl√© du mod√®le (nb, svm, lr, rf, gb, arabert)
            
        Returns:
            True si chargement r√©ussi, False sinon
        """
        # D√©j√† en cache
        if model_key in self.loaded_models:
            self.current_model_type = model_key
            logger.info(f"‚ôªÔ∏è Mod√®le {model_key} d√©j√† en cache")
            return True
        
        # Cas sp√©cial: AraBERT
        if model_key == 'arabert':
            return self._load_arabert()
        
        # Mod√®les traditionnels ML
        try:
            model_path = MODELS_DIR / f"{model_key}_model.pkl"
            if not model_path.exists():
                logger.error(f"‚ùå Mod√®le introuvable: {model_path}")
                return False
            
            model = load_model(str(model_path))
            self.loaded_models[model_key] = model
            self.current_model_type = model_key
            logger.info(f"‚úÖ Mod√®le {self.MODEL_NAMES[model_key]} charg√©")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement {model_key}: {e}")
            return False
    
    def _load_arabert(self) -> bool:
        """Charger le mod√®le AraBERT"""
        try:
            logger.info("ü§ñ Chargement AraBERT (peut prendre du temps)...")
            from src.models import AraBERTFakeNewsClassifier
            
            model = AraBERTFakeNewsClassifier()
            self.loaded_models['arabert'] = model
            self.current_model_type = 'arabert'
            logger.info("‚úÖ AraBERT charg√© avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå √âchec chargement AraBERT: {e}")
            return False
    
    def _apply_conan_heuristics(
        self, 
        text: str, 
        prediction: int, 
        probabilities: List[float]
    ) -> Tuple[int, List[float]]:
        """
        Appliquer les heuristiques de Detective Conan
        
        Comme Conan qui d√©tecte les indices subtils, cette fonction
        ajuste les pr√©dictions bas√©es sur des mots suspects
        
        Args:
            text: Texte original
            prediction: Pr√©diction initiale (0=fiable, 1=fake)
            probabilities: Probabilit√©s [prob_fiable, prob_fake]
            
        Returns:
            Tuple (nouvelle_prediction, nouvelles_probabilites)
        """
        text_lower = text.lower()
        proba_diff = abs(probabilities[0] - probabilities[1])
        
        # Chercher des indices suspects
        suspicion_score = sum(
            1 for keyword in self.SUSPICION_KEYWORDS 
            if keyword in text_lower
        )
        
        # Si indices suspects ET faible confiance du mod√®le
        if suspicion_score > 0 and proba_diff < 0.25:
            logger.info(f"üîç Conan d√©tecte {suspicion_score} indice(s) suspect(s)")
            
            new_proba = probabilities.copy()
            
            # Augmenter la probabilit√© de fake news
            if new_proba[1] < 0.65:
                boost = min(0.15 * suspicion_score, 0.30)
                new_proba[1] = min(new_proba[1] + boost, 0.75)
                new_proba[0] = 1.0 - new_proba[1]
                
                return 1, new_proba
        
        return prediction, probabilities
    
    def predict(
        self, 
        text: str, 
        model_key: str
    ) -> Tuple[int, List[float], Dict[str, Any]]:
        """
        Effectuer une pr√©diction sur un texte
        
        Args:
            text: Texte √† analyser
            model_key: Cl√© du mod√®le √† utiliser
            
        Returns:
            Tuple (prediction, probabilites, metadata)
        """
        if not text or not text.strip():
            raise ValueError("Le texte est vide")
        
        # Charger le mod√®le si n√©cessaire
        if model_key not in self.loaded_models:
            success = self.load_model(model_key)
            if not success:
                raise RuntimeError(f"Impossible de charger le mod√®le {model_key}")
        
        model = self.loaded_models[model_key]
        
        # Pr√©traitement
        processed_text = self.preprocessor.preprocess(text)
        
        # Pr√©diction selon le type de mod√®le
        if model_key == 'arabert':
            predictions, probas = model.predict([processed_text])
            prediction = int(predictions[0])
            proba = probas[0]
        else:
            if self.feature_extractor is None:
                raise RuntimeError("Extracteur de features non disponible")
            
            X = self.feature_extractor.transform([processed_text])
            prediction = int(model.predict(X)[0])
            proba = model.predict_proba(X)[0].tolist()
        
        # Appliquer les heuristiques de Conan
        final_pred, final_proba = self._apply_conan_heuristics(
            text, prediction, proba
        )
        
        # M√©tadonn√©es
        metadata = {
            'model': model_key,
            'model_name': self.MODEL_NAMES[model_key],
            'original_prediction': prediction,
            'adjusted_by_heuristics': (final_pred != prediction),
            'text_length': len(text),
            'word_count': len(text.split()),
            'processed_text_length': len(processed_text)
        }
        
        return final_pred, final_proba, metadata
    
    def get_available_models(self) -> List[str]:
        """Retourner la liste des mod√®les disponibles"""
        available = []
        
        # V√©rifier les mod√®les traditionnels
        for key in ['nb', 'svm', 'lr', 'rf', 'gb']:
            model_path = MODELS_DIR / f"{key}_model.pkl"
            if model_path.exists():
                available.append(self.MODEL_NAMES[key])
        
        # AraBERT (toujours disponible si d√©pendances OK)
        try:
            import transformers
            available.append(self.MODEL_NAMES['arabert'])
        except ImportError:
            pass
        
        return available
